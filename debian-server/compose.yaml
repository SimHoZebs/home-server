name: home-server

services:
  ##############################JELLYFIN##############################
  jellyfin:
    image: jellyfin/jellyfin
    container_name: jellyfin
    network_mode: "host"
    volumes:
      - ./jellyfin/config:/config
      - ./jellyfin/cache:/cache
      - type: bind
        source: /mnt/hdd1/media
        target: /media
      - type: bind
        source: /mnt/hdd1/media2
        target: /media2
        read_only: true
      # Optional - extra fonts to be used during transcoding with subtitle burn-in
      - type: bind
        source: /path/to/fonts
        target: /usr/local/share/fonts/custom
        read_only: true
    restart: "unless-stopped"
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Optional - alternative address used for autodiscovery
    environment:
      - JELLYFIN_PublishedServerUrl=${JELLYFIN_URL}
    # Optional - may be necessary for docker healthcheck to pass if running in host network mode
    extra_hosts:
      - "host.docker.internal:host-gateway"

  ##############################IMMICH##############################
  immich-server:
    container_name: immich_server
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    extends:
      file: hwaccel.transcoding.yml
      service: nvenc # set to one of [nvenc, quicksync, rkmpp, vaapi, vaapi-wsl] for accelerated transcoding
    volumes:
      # Do not edit the next line. If you want to change the media storage location on your system, edit the value of UPLOAD_LOCATION in the .env file
      - ${UPLOAD_LOCATION}:/usr/src/app/upload
      - /etc/localtime:/etc/localtime:ro
      - /mnt/hdd1/seafile/seafile-fuse:/seafile-external:ro
    env_file:
      - .env
    ports:
      - "${IMMICH_PORT:-2283}:2283"
    depends_on:
      - redis
      - database
    restart: always
    healthcheck:
      disable: false

  immich-machine-learning:
    container_name: immich_machine_learning
    # For hardware acceleration, add one of -[armnn, cuda, openvino] to the image tag.
    # Example tag: ${IMMICH_VERSION:-release}-cuda
    image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}-cuda
    extends:
      file: hwaccel.ml.yml
      service: cuda
    volumes:
      - model-cache-restore:/cache
    env_file:
      - .env
    restart: always
    healthcheck:
      disable: false

  redis:
    container_name: immich_redis
    image: docker.io/redis:6.2-alpine@sha256:2ba50e1ac3a0ea17b736ce9db2b0a9f6f8b85d4c27d5f5accc6a416d8f42c6d5
    healthcheck:
      test: redis-cli ping || exit 1
    restart: always

  database:
    container_name: immich_postgres
    image: docker.io/tensorchord/pgvecto-rs:pg14-v0.2.0@sha256:90724186f0a3517cf6914295b5ab410db9ce23190a2d9d0b9dd6463e3fa298f0
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_DB: ${DB_DATABASE_NAME}
      POSTGRES_INITDB_ARGS: "--data-checksums"
    volumes:
      - pgdata-restore:/var/lib/postgresql/data
      - /mnt/hdd1/media/backups:/backups
    healthcheck:
      test: pg_isready --dbname='${DB_DATABASE_NAME}' --username='${DB_USERNAME}' || exit 1; Chksum="$$(psql --dbname='${DB_DATABASE_NAME}' --username='${DB_USERNAME}' --tuples-only --no-align --command='SELECT COALESCE(SUM(checksum_failures), 0) FROM pg_stat_database')"; echo "checksum failure count is $$Chksum"; [ "$$Chksum" = '0' ] || exit 1
      interval: 5m
      start_interval: 30s
      start_period: 5m
    command:
      [
        "postgres",
        "-c",
        "shared_preload_libraries=vectors.so",
        "-c",
        'search_path="$$user", public, vectors',
        "-c",
        "logging_collector=on",
        "-c",
        "max_wal_size=2GB",
        "-c",
        "shared_buffers=512MB",
        "-c",
        "wal_compression=on",
      ]
    restart: always
  ##############################SEAFILE##############################
  db:
    image: mariadb:10.11
    container_name: seafile-mysql
    environment:
      - MYSQL_LOG_CONSOLE=true
      - MARIADB_AUTO_UPGRADE=1
      - MYSQL_ROOT_PASSWD=${SEAFILE_MYSQL_ROOT_PASSWORD}
    volumes:
      - /mnt/hdd1/seafile/seafile-mysql/db:/var/lib/mysql # Required, specifies the path to MySQL data persistent store.
    networks:
      - seafile-net
    restart: "unless-stopped"
    healthcheck:
      test:
        [
          "CMD",
          "mysqladmin",
          "ping",
          "-h",
          "localhost",
          "-u",
          "root",
          "--password=${SEAFILE_MYSQL_ROOT_PASSWORD}",
        ]
      interval: 10s
      timeout: 5s
      retries: 5

  memcached:
    image: memcached:1.6.18
    container_name: seafile-memcached
    entrypoint: memcached -m 256
    networks:
      - seafile-net
    restart: "unless-stopped"

  seafile:
    image: seafileltd/seafile-mc:11.0-latest
    container_name: seafile
    ports:
      - "${SEAFILE_PORT:-8585}:80"
    #     - "443:443"  # If https is enabled, cancel the comment.
    volumes:
      - /mnt/hdd1/seafile/seafile-data:/shared # Required, specifies the path to Seafile data persistent store.
      - type: bind
        source: /mnt/hdd1/seafile/seafile-fuse
        target: /seafile-fuse
        bind:
          propagation: rshared
    privileged: true
    cap_add:
      - SYS_ADMIN
    env_file: .env
    environment:
      - DB_HOST=db
      - DB_USER=${SEAFILE_DB_USER:-seafile}
      - DB_PASSWD=${SEAFILE_DB_PASSWORD:-seafile_password}
      - DB_NAME=${SEAFILE_DB_NAME:-seafile}
      - TIME_ZONE=${TIMEZONE:-Etc/UTC}
      - SEAFILE_SERVER_LETSENCRYPT=${SEAFILE_HTTPS:-false}
    depends_on:
      db:
        condition: service_healthy
      memcached:
        condition: service_started
    networks:
      - seafile-net
    restart: "unless-stopped"

  ##############################OLLAMA##############################
  ollama:
    container_name: ollama
    image: ollama/ollama:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia # Important for using NVIDIA runtime
    ports:
      - "${OLLAMA_PORT:-11434}:11434" # Expose the API port
    volumes:
      - ./ollama:/root/.ollama
    restart: "unless-stopped"

  ##############################UMAMI##############################
  umami:
    container_name: umami
    image: ghcr.io/umami-software/umami:postgresql-latest
    ports:
      - "${UMAMI_PORT:-3000}:3000"
    env_file: .env
    environment:
      DATABASE_URL: postgresql://${UMAMI_DB_USER}:${UMAMI_DB_PASSWORD}@db-umami:5432/${UMAMI_DB_NAME}
      DATABASE_TYPE: postgresql
    depends_on:
      db-umami:
        condition: service_healthy
    init: true
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "curl http://localhost:3000/api/heartbeat"]
      interval: 5s
      timeout: 5s
      retries: 5

  db-umami:
    container_name: db-umami
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ${UMAMI_DB_NAME}
      POSTGRES_USER: ${UMAMI_DB_USER}
      POSTGRES_PASSWORD: ${UMAMI_DB_PASSWORD}
    volumes:
      - umami-db-data:/var/lib/postgresql/data
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5

  ##############################STREAMER##############################
  streamer:
    container_name: streamer
    image: linuxserver/ffmpeg:latest
    restart: always
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ports:
      - "${SRT_PORT:-9998}:9998/udp"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
    command: >
      -i "srt://0.0.0.0:9998?mode=listener&latency=${SRT_LATENCY:-3000}"
      -fflags +genpts+discardcorrupt
      -c:v h264_nvenc -preset:v ${NVENC_PRESET:-p6} -b:v ${TWITCH_BITRATE:-6000k} -bufsize:v ${TWITCH_BUFSIZE:-12000k} -g ${TWITCH_GOP:-120} -keyint_min ${TWITCH_GOP:-120}
      -c:a copy
      -f flv rtmp://ingest.global-contribute.live-video.net/app/${TWITCH_KEY}
      -c:v copy -c:a copy
      -f flv rtmp://a.rtmp.youtube.com/live2/${YOUTUBE_KEY}
      -map 0:v -map 0:a
      -c:v h264_nvenc -preset ${NVENC_PRESET:-p6} \
                      -b:v ${TWITCH_BITRATE:-6000k} \
                      -maxrate ${TWITCH_BITRATE:-6000k} \
                      -bufsize ${TWITCH_BUFSIZE:-12000k} \
                      -g ${TWITCH_GOP:-120} -keyint_min ${TWITCH_GOP:-120} \
                      -pix_fmt yuv420p -bf 2
      -c:a copy
      -f flv rtmp://live.twitch.tv/app/${TWITCH_KEY}
    volumes:
      - /tmp:/tmp

networks:
  seafile-net:

volumes:
  pgdata-restore:
  model-cache-restore:
  umami-db-data:
